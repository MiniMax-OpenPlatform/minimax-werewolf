version: '3.8'

services:
  ai-werewolf:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        PROXY_URL: http://pac-internal.xaminim.com:3129
        NO_PROXY: localhost,127.0.0.1,*.xaminim.com,10.0.0.0/8
    image: ai-werewolf:latest
    container_name: ai-werewolf-game
    restart: unless-stopped
    ports:
      - "80:80"
    environment:
      # AI Provider Configuration
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - AI_MODEL=${AI_MODEL:-google/gemini-2.5-flash}

      # Langfuse Telemetry (optional)
      - LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY:-}
      - LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY:-}
      - LANGFUSE_BASEURL=${LANGFUSE_BASEURL:-https://us.cloud.langfuse.com}

      # Server Configuration
      - PORT=3001
      - HOST=0.0.0.0
      - NODE_ENV=production

      # Network proxy configuration for runtime
      - http_proxy=http://pac-internal.xaminim.com:3129
      - https_proxy=http://pac-internal.xaminim.com:3129
      - ftp_proxy=http://pac-internal.xaminim.com:3129
      - no_proxy=localhost,127.0.0.1,*.xaminim.com,10.0.0.0/8
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
